{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPU Detection and Testing\n",
        "\n",
        "This notebook demonstrates how to detect and use GPUs in a remote Jupyter environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if GPU is available via nvidia-smi\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, check=True, timeout=10)\n",
        "    print(\"✓ nvidia-smi is available\")\n",
        "    print(f\"\\nGPU Information:\\n{result.stdout}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ nvidia-smi not available: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check PyTorch CUDA availability\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA version: {torch.version.cuda}\")\n",
        "        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    else:\n",
        "        print(\"No CUDA devices found\")\n",
        "except ImportError:\n",
        "    print(\"PyTorch not installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple GPU computation test\n",
        "try:\n",
        "    import torch\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        # Create tensors on GPU\n",
        "        x = torch.randn(1000, 1000, device='cuda')\n",
        "        y = torch.randn(1000, 1000, device='cuda')\n",
        "        \n",
        "        # Perform matrix multiplication on GPU\n",
        "        z = torch.matmul(x, y)\n",
        "        \n",
        "        print(\"✓ Successfully performed computation on GPU\")\n",
        "        print(f\"  Result shape: {z.shape}\")\n",
        "        print(f\"  Result device: {z.device}\")\n",
        "        print(f\"  Result mean: {z.mean().item():.4f}\")\n",
        "    else:\n",
        "        print(\"No GPU available for computation\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Tests\n",
        "\n",
        "You can run the test suite to verify everything is working:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run pytest tests\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Change to project root\n",
        "import os\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "os.chdir(project_root)\n",
        "\n",
        "# Run pytest\n",
        "result = subprocess.run(\n",
        "    [sys.executable, '-m', 'pytest', 'cloud-gpu/tests/', '-v'],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"Errors:\", result.stderr)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
