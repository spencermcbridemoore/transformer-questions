{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vast.ai A100 Instance Testing\n",
    "\n",
    "This notebook automates the full lifecycle of renting a Vast.ai GPU instance, testing a HuggingFace model, and cleaning up.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Search** for cheapest A100 or H100 instance (<$3.00/hr)\n",
    "2. **Launch** the instance\n",
    "3. **Connect** via SSH and upload scripts\n",
    "4. **Setup** environment on remote instance\n",
    "5. **Evaluate** model (download, test tokenization and inference)\n",
    "6. **Cleanup** by destroying the instance\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- VAST_API_KEY set in `.env` file\n",
    "- Library modules in `cloud-gpu/lib/`\n",
    "- Remote scripts in `cloud-gpu/remote_scripts/`\n",
    "- Required packages: `vastai-sdk`, `paramiko`, `python-dotenv`\n",
    "\n",
    "## Architecture\n",
    "\n",
    "This notebook uses a clean library-based architecture:\n",
    "- **VastManager**: Instance lifecycle management\n",
    "- **RemoteExecutor**: SSH/SCP file upload and command execution\n",
    "- **Remote Scripts**: Actual code executed on remote instance (no multiline strings!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Library Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add lib directory to path (relative to notebook location)\n",
    "lib_path = Path('..') / 'lib'\n",
    "sys.path.insert(0, str(lib_path.resolve()))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import library modules\n",
    "from vast_manager import VastManager\n",
    "from remote_executor import RemoteExecutor\n",
    "from model_evaluator import ModelEvaluator\n",
    "\n",
    "print(\"[OK] Library modules imported successfully\")\n",
    "\n",
    "# Configuration\n",
    "MAX_PRICE_PER_HOUR = 3.0  # $3.00/hour\n",
    "GPU_TYPES = [\"A100\", \"H100\"]  # Search for A100 or H100\n",
    "MODEL_NAME = \"gpt2\"  # Small model for testing\n",
    "\n",
    "# Initialize Vast.ai manager\n",
    "manager = VastManager()\n",
    "print(\"[OK] VastManager initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for remote scripts (relative to notebook location)\n",
    "REMOTE_SCRIPTS_DIR = Path('..') / 'remote_scripts'\n",
    "\n",
    "print(f\"[INFO] Remote scripts directory: {REMOTE_SCRIPTS_DIR.resolve()}\")\n",
    "print(f\"[INFO] Configuration:\")\n",
    "print(f\"  GPU Types: {', '.join(GPU_TYPES)}\")\n",
    "print(f\"  Max Price: ${MAX_PRICE_PER_HOUR}/hour\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search and Launch Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for instances (A100 or H100)\n",
    "print(f\"Searching for {' or '.join(GPU_TYPES)} instances under ${MAX_PRICE_PER_HOUR}/hour...\")\n",
    "offers = manager.search_instances(\n",
    "    gpu_types=GPU_TYPES,\n",
    "    max_price_per_hour=MAX_PRICE_PER_HOUR,\n",
    "    limit=50\n",
    ")\n",
    "\n",
    "# Select cheapest offer\n",
    "selected_offer = manager.select_cheapest(offers)\n",
    "selected_price = selected_offer.get('dph_total', selected_offer.get('dph', selected_offer.get('price', 0)))\n",
    "\n",
    "print(f\"\\n[OK] Selected instance:\")\n",
    "print(f\"  GPU: {selected_offer.get('gpu_name', 'Unknown')}\")\n",
    "print(f\"  Price: ${selected_price:.2f}/hour\")\n",
    "print(f\"  Offer ID: {selected_offer.get('id', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch instance\n",
    "print(\"\\nLaunching instance...\")\n",
    "print(\"[WARNING] This will start billing immediately!\")\n",
    "\n",
    "instance_id = manager.launch_instance(\n",
    "    image=\"pytorch/pytorch:latest\",\n",
    "    disk=10\n",
    ")\n",
    "\n",
    "print(f\"[OK] Instance launched: {instance_id}\")\n",
    "print(\"[INFO] Billing has started - ensure cleanup runs even if errors occur!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wait for Instance to be Ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch instance\n",
    "# Note: Based on Vast.ai SDK, use create_instance() with id= parameter\n",
    "\n",
    "print(\"Launching instance...\")\n",
    "print(\"[WARNING] This will start billing immediately!\")\n",
    "\n",
    "# Use HuggingFace/PyTorch pre-configured image\n",
    "# Common images: pytorch/pytorch, huggingface/transformers-pytorch-gpu\n",
    "image = \"pytorch/pytorch:latest\"  # Adjust based on availability\n",
    "\n",
    "# Track start time for cost calculation\n",
    "INSTANCE_START_TIME = time.time()\n",
    "\n",
    "# Create instance using create_instance with id= parameter (offer ID)\n",
    "try:\n",
    "    instance = client.create_instance(\n",
    "        id=SELECTED_OFFER_ID,  # offer ID as keyword argument\n",
    "        image=image,\n",
    "        disk=10,  # GB (note: parameter is 'disk', not 'disk_space')\n",
    "    )\n",
    "    \n",
    "    # create_instance returns {'success': True, 'new_contract': <instance_id>}\n",
    "    # The instance ID is in the 'new_contract' field\n",
    "    if isinstance(instance, dict):\n",
    "        INSTANCE_ID = instance.get('new_contract') or instance.get('id')\n",
    "    else:\n",
    "        INSTANCE_ID = instance\n",
    "    \n",
    "    if not INSTANCE_ID:\n",
    "        raise ValueError(\"Failed to get instance ID from create_instance response\")\n",
    "    \n",
    "    print(f\"[OK] Instance created: {INSTANCE_ID}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to launch instance: {e}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(\"Available instance methods:\", [m for m in dir(client) if 'instance' in m.lower()])\n",
    "    INSTANCE_START_TIME = None  # Reset since launch failed\n",
    "    raise\n",
    "\n",
    "print(f\"[INFO] Instance ID: {INSTANCE_ID}\")\n",
    "print(\"[INFO] Billing has started - ensure cleanup runs even if errors occur!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for instance to be ready\n",
    "print(\"Waiting for instance to be ready...\")\n",
    "max_wait_time = 300  # 5 minutes timeout\n",
    "start_time = time.time()\n",
    "poll_interval = 10  # Check every 10 seconds\n",
    "\n",
    "INSTANCE_INFO = None\n",
    "while time.time() - start_time < max_wait_time:\n",
    "    try:\n",
    "        instances = client.show_instances()\n",
    "        # Find our instance\n",
    "        if isinstance(instances, list):\n",
    "            instance_list = instances\n",
    "        elif isinstance(instances, dict):\n",
    "            instance_list = instances.get('instances', [instances] if instances else [])\n",
    "        else:\n",
    "            instance_list = []\n",
    "        \n",
    "        for inst in instance_list:\n",
    "            if isinstance(inst, dict) and str(inst.get('id')) == str(INSTANCE_ID):\n",
    "                status = inst.get('status', inst.get('state', inst.get('actual_status', 'unknown')))\n",
    "                ip = inst.get('public_ipaddr', inst.get('ip'))\n",
    "                \n",
    "                # Print status every few attempts\n",
    "                if (time.time() - start_time) % (poll_interval * 3) < poll_interval:\n",
    "                    print(f\"  Status: {status}, IP: {ip}\")\n",
    "                \n",
    "                # Consider instance ready if it has an IP address (even if status is 'unknown')\n",
    "                # Instances often have IPs assigned before status changes to 'running'\n",
    "                if ip and ip != 'None' and ip.strip():\n",
    "                    INSTANCE_INFO = inst\n",
    "                    print(f\"[OK] Instance is ready! Status: {status}, IP: {ip}\")\n",
    "                    break\n",
    "                elif status in ['running', 'ready', 'online', 'active']:\n",
    "                    INSTANCE_INFO = inst\n",
    "                    print(f\"[OK] Instance is ready! Status: {status}\")\n",
    "                    break\n",
    "                elif status in ['error', 'failed', 'terminated']:\n",
    "                    raise Exception(f\"Instance failed with status: {status}\")\n",
    "        \n",
    "        if INSTANCE_INFO:\n",
    "            break\n",
    "            \n",
    "        time.sleep(poll_interval)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Error checking status: {e}\")\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "if not INSTANCE_INFO:\n",
    "    raise TimeoutError(f\"Instance {INSTANCE_ID} did not become ready within {max_wait_time} seconds\")\n",
    "\n",
    "# Extract connection info\n",
    "SSH_HOST = INSTANCE_INFO.get('public_ipaddr', INSTANCE_INFO.get('ip', None))\n",
    "SSH_PORT = INSTANCE_INFO.get('ssh_port', 22)\n",
    "SSH_USER = INSTANCE_INFO.get('ssh_username', 'root')\n",
    "\n",
    "print(f\"[OK] Instance ready!\")\n",
    "print(f\"  IP: {SSH_HOST}\")\n",
    "print(f\"  SSH User: {SSH_USER}\")\n",
    "print(f\"  SSH Port: {SSH_PORT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Connect and Setup Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SSH key from Vast.ai or use existing\n",
    "# Vast.ai typically provides SSH keys - check instance info or API methods\n",
    "# For now, we'll assume SSH key is set up or provided\n",
    "\n",
    "# Get SSH key if available\n",
    "ssh_key_path = None\n",
    "ssh_private_key = None\n",
    "\n",
    "# Try to get SSH key from Vast.ai\n",
    "try:\n",
    "    ssh_keys = client.show_ssh_keys()\n",
    "    if ssh_keys:\n",
    "        # Use first available key or the one associated with instance\n",
    "        if isinstance(ssh_keys, list) and len(ssh_keys) > 0:\n",
    "            ssh_key_info = ssh_keys[0]\n",
    "            # SSH key might be in instance info or need to be retrieved\n",
    "            pass\n",
    "except Exception as e:\n",
    "    print(f\"[WARNING] Could not retrieve SSH keys: {e}\")\n",
    "\n",
    "# For now, we'll use password or assume SSH key is configured\n",
    "# In production, you'd want to handle SSH key setup properly\n",
    "print(\"[INFO] SSH connection setup\")\n",
    "print(f\"  You may need to configure SSH keys manually\")\n",
    "print(f\"  Or use Vast.ai's web-based terminal/Jupyter interface\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute commands via SSH\n",
    "def execute_ssh_command(host, port, username, command, ssh_key=None, timeout=30):\n",
    "    \"\"\"\n",
    "    Execute a command on remote instance via SSH.\n",
    "    \n",
    "    Note: This is a simplified version. In practice, you might:\n",
    "    - Use Vast.ai's API methods for remote execution\n",
    "    - Use their Jupyter interface\n",
    "    - Use their web terminal\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ssh = paramiko.SSHClient()\n",
    "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        \n",
    "        # Connect with key or password\n",
    "        if ssh_key:\n",
    "            ssh.connect(host, port=port, username=username, key_filename=ssh_key, timeout=timeout)\n",
    "        else:\n",
    "            # Try passwordless (if configured)\n",
    "            # Or prompt for password\n",
    "            print(\"[WARNING] No SSH key provided - connection may fail\")\n",
    "            print(\"  Consider using Vast.ai's Jupyter interface instead\")\n",
    "            return None, None, None\n",
    "        \n",
    "        stdin, stdout, stderr = ssh.exec_command(command, timeout=timeout)\n",
    "        exit_status = stdout.channel.recv_exit_status()\n",
    "        output = stdout.read().decode()\n",
    "        error = stderr.read().decode()\n",
    "        \n",
    "        ssh.close()\n",
    "        return output, error, exit_status\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] SSH connection failed: {e}\")\n",
    "        return None, str(e), 1\n",
    "\n",
    "print(\"[INFO] SSH helper function defined\")\n",
    "print(\"[NOTE] For this demo, we'll use a simplified approach\")\n",
    "print(\"  You may need to use Vast.ai's web interface or configure SSH keys properly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use Vast.ai's remote execution or Jupyter interface\n",
    "# For this notebook, we'll demonstrate the concept with simplified execution\n",
    "\n",
    "print(\"[INFO] Setting up remote environment\")\n",
    "print(\"  In practice, you would:\")\n",
    "print(\"  1. Connect via SSH or Vast.ai web terminal\")\n",
    "print(\"  2. Install dependencies: pip install transformers torch\")\n",
    "print(\"  3. Verify CUDA: python -c 'import torch; print(torch.cuda.is_available())'\")\n",
    "\n",
    "# For demonstration, we'll show what commands would be run\n",
    "setup_commands = [\n",
    "    \"pip install transformers torch accelerate --quiet\",\n",
    "    \"python -c 'import torch; print(f\\\"CUDA available: {torch.cuda.is_available()}\\\")'\",\n",
    "    \"python -c 'import torch; print(f\\\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \\\"N/A\\\"}\\\")'\"\n",
    "]\n",
    "\n",
    "print(\"\\nCommands to run on remote:\")\n",
    "for cmd in setup_commands:\n",
    "    print(f\"  $ {cmd}\")\n",
    "\n",
    "# If SSH is configured, uncomment to actually execute:\n",
    "# for cmd in setup_commands:\n",
    "#     output, error, status = execute_ssh_command(SSH_HOST, SSH_PORT, SSH_USER, cmd)\n",
    "#     print(f\"Command: {cmd}\")\n",
    "#     print(f\"Output: {output}\")\n",
    "#     if error:\n",
    "#         print(f\"Error: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model on Remote Instance\n",
    "\n",
    "Execute the uploaded `evaluate_model.py` script on the remote instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute model evaluation script on remote instance\n",
    "if executor._ssh_client:\n",
    "    print(f\"Evaluating model: {MODEL_NAME}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    evaluate_script = f\"{remote_scripts_dir}/evaluate_model.py\"\n",
    "    output, error, status = executor.execute_command(\n",
    "        f\"python3 {evaluate_script} {MODEL_NAME}\",\n",
    "        timeout=300  # 5 minutes for model download\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluation output:\")\n",
    "    print(output)\n",
    "    if error:\n",
    "        print(\"Errors:\")\n",
    "        print(error)\n",
    "    \n",
    "    if status == 0:\n",
    "        print(\"\\n[OK] Model evaluation complete!\")\n",
    "    else:\n",
    "        print(f\"\\n[WARNING] Evaluation completed with exit code {status}\")\n",
    "else:\n",
    "    print(\"[INFO] Skipping model evaluation (not connected)\")\n",
    "    print(f\"  To evaluate manually, run on remote instance:\")\n",
    "    print(f\"  python {remote_scripts_dir}/evaluate_model.py {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup and Teardown\n",
    "\n",
    "**IMPORTANT:** Always destroy the instance when done to avoid unexpected charges!\n",
    "\n",
    "Close SSH connection and destroy the instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display cost\n",
    "import time\n",
    "\n",
    "cost = manager.calculate_cost(selected_price if 'selected_price' in locals() else None)\n",
    "if cost is not None:\n",
    "    runtime_seconds = time.time() - manager.instance_start_time\n",
    "    runtime_minutes = runtime_seconds / 60\n",
    "    print(f\"Instance runtime: ~{runtime_minutes:.1f} minutes ({runtime_seconds:.0f} seconds)\")\n",
    "    print(f\"Hourly rate: ${selected_price:.2f}/hour\")\n",
    "    print(f\"Estimated cost: ~${cost:.4f}\")\n",
    "else:\n",
    "    print(\"[WARNING] Could not calculate cost\")\n",
    "\n",
    "# Close SSH connection\n",
    "if executor._ssh_client:\n",
    "    executor.disconnect()\n",
    "    print(\"[OK] SSH connection closed\")\n",
    "\n",
    "print(\"\\n[WARNING] Destroying instance now to stop billing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destroy instance using manager\n",
    "if manager.instance_id:\n",
    "    success = manager.destroy_instance()\n",
    "    if success:\n",
    "        print(\"[OK] Instance destroyed successfully\")\n",
    "    else:\n",
    "        print(\"[WARNING] Instance destruction may have failed - verify in console\")\n",
    "else:\n",
    "    print(\"[WARNING] No instance ID to destroy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify instance is destroyed (optional check)\n",
    "print(\"Verifying instance termination...\")\n",
    "import time\n",
    "time.sleep(5)  # Wait a moment for termination to propagate\n",
    "\n",
    "# Note: The manager.destroy_instance() already handles this, but you can verify manually\n",
    "print(\"[INFO] Instance should be destroyed\")\n",
    "print(\"[INFO] Always verify in Vast.ai console: https://console.vast.ai/instances/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **Completed:**\n",
    "- Searched for cheapest A100 instance (<$1.50/hr)\n",
    "- Launched instance on Vast.ai\n",
    "- Connected via SSH and uploaded scripts\n",
    "- Set up remote environment\n",
    "- Evaluated HuggingFace model (GPT-2)\n",
    "- Tested tokenization and inference\n",
    "- Cleaned up by destroying instance\n",
    "\n",
    "**Architecture Improvements:**\n",
    "- ✅ Clean library-based code (no multiline strings!)\n",
    "- ✅ Separated concerns: local orchestration vs remote execution\n",
    "- ✅ Reusable scripts in `remote_scripts/`\n",
    "- ✅ Reusable library modules in `lib/`\n",
    "\n",
    "**Notes:**\n",
    "- SSH connection may require SSH key configuration\n",
    "- Scripts are uploaded via SCP (no heredoc strings)\n",
    "- Always verify instance destruction in Vast.ai console\n",
    "- Monitor your Vast.ai dashboard for actual costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling & Safety\n",
    "\n",
    "**Important:** \n",
    "- The `manager.destroy_instance()` method handles cleanup\n",
    "- Always wrap notebook execution in try/except to ensure cleanup runs\n",
    "- **Always verify** in Vast.ai console that instances are destroyed\n",
    "\n",
    "**Manual Cleanup:**\n",
    "- Console: https://console.vast.ai/instances/\n",
    "- Using manager: `manager.destroy_instance()`\n",
    "- Using script: `python cleanup_instance.py <instance_id>`\n",
    "\n",
    "**Architecture:**\n",
    "- Local code: Orchestration in notebook\n",
    "- Remote code: Executed via uploaded scripts (no multiline strings!)\n",
    "- Library code: Reusable modules in `cloud-gpu/lib/`\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
