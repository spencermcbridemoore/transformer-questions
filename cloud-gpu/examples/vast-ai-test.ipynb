{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vast.ai A100 Instance Testing\n",
        "\n",
        "This notebook automates the full lifecycle of renting a Vast.ai GPU instance, testing a HuggingFace model, and cleaning up.\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. **Search** for cheapest geographically close A100 instance (<$1/hr)\n",
        "2. **Launch** the instance\n",
        "3. **Connect** via SSH and set up environment\n",
        "4. **Download** a small HuggingFace model\n",
        "5. **Test** tokenization and inference\n",
        "6. **Cleanup** by destroying the instance\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- VAST_API_KEY set in `.env` file\n",
        "- vastai-sdk installed: `pip install vastai-sdk`\n",
        "- paramiko for SSH: `pip install paramiko`\n",
        "- transformers: `pip install transformers`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Verify API key is loaded\n",
        "api_key = os.getenv('VAST_API_KEY')\n",
        "if not api_key or api_key == 'your_vast_api_key_here':\n",
        "    raise ValueError(\"VAST_API_KEY not found in .env file. Please set it first.\")\n",
        "\n",
        "print(f\"[OK] API key loaded (length: {len(api_key)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Vast.ai SDK\n",
        "try:\n",
        "    from vastai import VastAI\n",
        "    print(\"[OK] vastai-sdk imported successfully\")\n",
        "except ImportError:\n",
        "    raise ImportError(\"vastai-sdk not installed. Install with: pip install vastai-sdk\")\n",
        "\n",
        "# Import SSH library\n",
        "try:\n",
        "    import paramiko\n",
        "    print(\"[OK] paramiko imported successfully\")\n",
        "except ImportError:\n",
        "    raise ImportError(\"paramiko not installed. Install with: pip install paramiko\")\n",
        "\n",
        "# Import ML libraries\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "    import torch\n",
        "    print(\"[OK] transformers and torch imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"[WARNING] transformers/torch not installed locally (will be needed on remote instance)\")\n",
        "\n",
        "# Initialize VastAI client\n",
        "client = VastAI(api_key=api_key)\n",
        "print(\"[OK] VastAI client initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Search for A100 Instances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "MAX_PRICE_PER_HOUR = 1.0  # $1/hour\n",
        "GPU_TYPE = \"A100\"\n",
        "\n",
        "print(f\"Searching for {GPU_TYPE} instances under ${MAX_PRICE_PER_HOUR}/hour...\")\n",
        "\n",
        "# Search for A100 instances\n",
        "offers = client.search_offers(\n",
        "    query=f\"gpu_name:{GPU_TYPE}\",\n",
        "    order=\"score\",\n",
        "    limit=50  # Get more results to filter\n",
        ")\n",
        "\n",
        "print(f\"[INFO] Raw offers type: {type(offers)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process offers - handle different return formats\n",
        "if offers is None:\n",
        "    print(\"[ERROR] No offers returned from API\")\n",
        "    available_offers = []\n",
        "elif isinstance(offers, list):\n",
        "    available_offers = offers\n",
        "elif isinstance(offers, dict):\n",
        "    # Check if offers are in a nested structure\n",
        "    available_offers = offers.get('offers', offers.get('instances', []))\n",
        "    if not available_offers:\n",
        "        available_offers = [offers] if offers else []\n",
        "else:\n",
        "    print(f\"[WARNING] Unexpected offers format: {type(offers)}\")\n",
        "    available_offers = []\n",
        "\n",
        "print(f\"[INFO] Total offers received: {len(available_offers)}\")\n",
        "\n",
        "# Filter by price and GPU type\n",
        "filtered_offers = []\n",
        "for offer in available_offers:\n",
        "    if not isinstance(offer, dict):\n",
        "        continue\n",
        "    \n",
        "    # Get price (may be in different fields)\n",
        "    price = offer.get('dph_total', offer.get('dph', offer.get('price', float('inf'))))\n",
        "    gpu_name = offer.get('gpu_name', '')\n",
        "    \n",
        "    # Filter: A100 in name and price < MAX_PRICE_PER_HOUR\n",
        "    if GPU_TYPE.upper() in gpu_name.upper() and price < MAX_PRICE_PER_HOUR:\n",
        "        filtered_offers.append(offer)\n",
        "\n",
        "print(f\"[INFO] Filtered offers matching criteria: {len(filtered_offers)}\")\n",
        "\n",
        "if not filtered_offers:\n",
        "    print(f\"[ERROR] No {GPU_TYPE} instances found under ${MAX_PRICE_PER_HOUR}/hour\")\n",
        "    print(\"Try increasing MAX_PRICE_PER_HOUR or checking availability\")\n",
        "else:\n",
        "    # Sort by price ascending\n",
        "    filtered_offers.sort(key=lambda x: x.get('dph_total', x.get('dph', x.get('price', float('inf')))))\n",
        "    \n",
        "    # Select cheapest\n",
        "    selected_offer = filtered_offers[0]\n",
        "    selected_price = selected_offer.get('dph_total', selected_offer.get('dph', selected_offer.get('price', 0)))\n",
        "    \n",
        "    print(f\"[OK] Selected instance:\")\n",
        "    print(f\"  GPU: {selected_offer.get('gpu_name', 'Unknown')}\")\n",
        "    print(f\"  Price: ${selected_price:.2f}/hour\")\n",
        "    print(f\"  Offer ID: {selected_offer.get('id', 'N/A')}\")\n",
        "    if 'geolocation' in selected_offer:\n",
        "        print(f\"  Location: {selected_offer.get('geolocation', 'N/A')}\")\n",
        "    \n",
        "    # Store for later use\n",
        "    SELECTED_OFFER = selected_offer\n",
        "    SELECTED_OFFER_ID = selected_offer.get('id')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Launch Instance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Launch instance\n",
        "# Note: You may need to adjust parameters based on Vast.ai API documentation\n",
        "# Common parameters: image, disk_space, env_vars, etc.\n",
        "\n",
        "print(\"Launching instance...\")\n",
        "print(\"[WARNING] This will start billing immediately!\")\n",
        "\n",
        "# Use HuggingFace/PyTorch pre-configured image\n",
        "# Common images: pytorch/pytorch, huggingface/transformers-pytorch-gpu\n",
        "image = \"pytorch/pytorch:latest\"  # Adjust based on availability\n",
        "\n",
        "# Create instance\n",
        "# Note: Actual method name may vary - check VastAI client methods\n",
        "try:\n",
        "    instance = client.launch_instance(\n",
        "        offer_id=SELECTED_OFFER_ID,\n",
        "        image=image,\n",
        "        disk_space=10,  # GB\n",
        "        # auto_destroy=True,  # Safety: auto-destroy after inactivity\n",
        "    )\n",
        "    INSTANCE_ID = instance.get('id') if isinstance(instance, dict) else instance\n",
        "    print(f\"[OK] Instance launched: {INSTANCE_ID}\")\n",
        "except AttributeError:\n",
        "    # Try alternative method names\n",
        "    try:\n",
        "        instance = client.create_instance(\n",
        "            offer_id=SELECTED_OFFER_ID,\n",
        "            image=image,\n",
        "        )\n",
        "        INSTANCE_ID = instance.get('id') if isinstance(instance, dict) else instance\n",
        "        print(f\"[OK] Instance created: {INSTANCE_ID}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to launch instance: {e}\")\n",
        "        print(\"Check VastAI client methods: client.launch_instance() or client.create_instance()\")\n",
        "        raise\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] Failed to launch instance: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wait for instance to be ready\n",
        "print(\"Waiting for instance to be ready...\")\n",
        "max_wait_time = 300  # 5 minutes timeout\n",
        "start_time = time.time()\n",
        "poll_interval = 10  # Check every 10 seconds\n",
        "\n",
        "INSTANCE_INFO = None\n",
        "while time.time() - start_time < max_wait_time:\n",
        "    try:\n",
        "        instances = client.show_instances()\n",
        "        # Find our instance\n",
        "        if isinstance(instances, list):\n",
        "            instance_list = instances\n",
        "        elif isinstance(instances, dict):\n",
        "            instance_list = instances.get('instances', [instances] if instances else [])\n",
        "        else:\n",
        "            instance_list = []\n",
        "        \n",
        "        for inst in instance_list:\n",
        "            if isinstance(inst, dict) and str(inst.get('id')) == str(INSTANCE_ID):\n",
        "                status = inst.get('status', inst.get('state', 'unknown'))\n",
        "                print(f\"  Status: {status}\")\n",
        "                \n",
        "                if status in ['running', 'ready', 'online']:\n",
        "                    INSTANCE_INFO = inst\n",
        "                    print(\"[OK] Instance is ready!\")\n",
        "                    break\n",
        "                elif status in ['error', 'failed', 'terminated']:\n",
        "                    raise Exception(f\"Instance failed with status: {status}\")\n",
        "        \n",
        "        if INSTANCE_INFO:\n",
        "            break\n",
        "            \n",
        "        time.sleep(poll_interval)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Error checking status: {e}\")\n",
        "        time.sleep(poll_interval)\n",
        "\n",
        "if not INSTANCE_INFO:\n",
        "    raise TimeoutError(f\"Instance {INSTANCE_ID} did not become ready within {max_wait_time} seconds\")\n",
        "\n",
        "# Extract connection info\n",
        "SSH_HOST = INSTANCE_INFO.get('public_ipaddr', INSTANCE_INFO.get('ip', None))\n",
        "SSH_PORT = INSTANCE_INFO.get('ssh_port', 22)\n",
        "SSH_USER = INSTANCE_INFO.get('ssh_username', 'root')\n",
        "\n",
        "print(f\"[OK] Instance ready!\")\n",
        "print(f\"  IP: {SSH_HOST}\")\n",
        "print(f\"  SSH User: {SSH_USER}\")\n",
        "print(f\"  SSH Port: {SSH_PORT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Connect and Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get SSH key from Vast.ai or use existing\n",
        "# Vast.ai typically provides SSH keys - check instance info or API methods\n",
        "# For now, we'll assume SSH key is set up or provided\n",
        "\n",
        "# Get SSH key if available\n",
        "ssh_key_path = None\n",
        "ssh_private_key = None\n",
        "\n",
        "# Try to get SSH key from Vast.ai\n",
        "try:\n",
        "    ssh_keys = client.show_ssh_keys()\n",
        "    if ssh_keys:\n",
        "        # Use first available key or the one associated with instance\n",
        "        if isinstance(ssh_keys, list) and len(ssh_keys) > 0:\n",
        "            ssh_key_info = ssh_keys[0]\n",
        "            # SSH key might be in instance info or need to be retrieved\n",
        "            pass\n",
        "except Exception as e:\n",
        "    print(f\"[WARNING] Could not retrieve SSH keys: {e}\")\n",
        "\n",
        "# For now, we'll use password or assume SSH key is configured\n",
        "# In production, you'd want to handle SSH key setup properly\n",
        "print(\"[INFO] SSH connection setup\")\n",
        "print(f\"  You may need to configure SSH keys manually\")\n",
        "print(f\"  Or use Vast.ai's web-based terminal/Jupyter interface\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to execute commands via SSH\n",
        "def execute_ssh_command(host, port, username, command, ssh_key=None, timeout=30):\n",
        "    \"\"\"\n",
        "    Execute a command on remote instance via SSH.\n",
        "    \n",
        "    Note: This is a simplified version. In practice, you might:\n",
        "    - Use Vast.ai's API methods for remote execution\n",
        "    - Use their Jupyter interface\n",
        "    - Use their web terminal\n",
        "    \"\"\"\n",
        "    try:\n",
        "        ssh = paramiko.SSHClient()\n",
        "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
        "        \n",
        "        # Connect with key or password\n",
        "        if ssh_key:\n",
        "            ssh.connect(host, port=port, username=username, key_filename=ssh_key, timeout=timeout)\n",
        "        else:\n",
        "            # Try passwordless (if configured)\n",
        "            # Or prompt for password\n",
        "            print(\"[WARNING] No SSH key provided - connection may fail\")\n",
        "            print(\"  Consider using Vast.ai's Jupyter interface instead\")\n",
        "            return None, None, None\n",
        "        \n",
        "        stdin, stdout, stderr = ssh.exec_command(command, timeout=timeout)\n",
        "        exit_status = stdout.channel.recv_exit_status()\n",
        "        output = stdout.read().decode()\n",
        "        error = stderr.read().decode()\n",
        "        \n",
        "        ssh.close()\n",
        "        return output, error, exit_status\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] SSH connection failed: {e}\")\n",
        "        return None, str(e), 1\n",
        "\n",
        "print(\"[INFO] SSH helper function defined\")\n",
        "print(\"[NOTE] For this demo, we'll use a simplified approach\")\n",
        "print(\"  You may need to use Vast.ai's web interface or configure SSH keys properly\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: Use Vast.ai's remote execution or Jupyter interface\n",
        "# For this notebook, we'll demonstrate the concept with simplified execution\n",
        "\n",
        "print(\"[INFO] Setting up remote environment\")\n",
        "print(\"  In practice, you would:\")\n",
        "print(\"  1. Connect via SSH or Vast.ai web terminal\")\n",
        "print(\"  2. Install dependencies: pip install transformers torch\")\n",
        "print(\"  3. Verify CUDA: python -c 'import torch; print(torch.cuda.is_available())'\")\n",
        "\n",
        "# For demonstration, we'll show what commands would be run\n",
        "setup_commands = [\n",
        "    \"pip install transformers torch accelerate --quiet\",\n",
        "    \"python -c 'import torch; print(f\\\"CUDA available: {torch.cuda.is_available()}\\\")'\",\n",
        "    \"python -c 'import torch; print(f\\\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \\\"N/A\\\"}\\\")'\"\n",
        "]\n",
        "\n",
        "print(\"\\nCommands to run on remote:\")\n",
        "for cmd in setup_commands:\n",
        "    print(f\"  $ {cmd}\")\n",
        "\n",
        "# If SSH is configured, uncomment to actually execute:\n",
        "# for cmd in setup_commands:\n",
        "#     output, error, status = execute_ssh_command(SSH_HOST, SSH_PORT, SSH_USER, cmd)\n",
        "#     print(f\"Command: {cmd}\")\n",
        "#     print(f\"Output: {output}\")\n",
        "#     if error:\n",
        "#         print(f\"Error: {error}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Download and Test Model\n",
        "\n",
        "**Note:** For actual execution, you would run this on the remote instance.\n",
        "For this demo, we'll show the code that would run remotely.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model selection - use small model for quick testing\n",
        "MODEL_NAME = \"gpt2\"  # Small, ~500MB model\n",
        "\n",
        "print(f\"Downloading model: {MODEL_NAME}\")\n",
        "\n",
        "# Code to run on remote instance:\n",
        "remote_code = f\"\"\"\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load tokenizer and model\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{MODEL_NAME}\")\n",
        "print(\"Loading model...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"{MODEL_NAME}\")\n",
        "\n",
        "# Move to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to(\"cuda\")\n",
        "    print(f\"Model moved to GPU: {{torch.cuda.get_device_name(0)}}\")\n",
        "else:\n",
        "    print(\"CUDA not available - using CPU\")\n",
        "\n",
        "# Test tokenization\n",
        "test_text = \"Hello, how are you today?\"\n",
        "print(f\"\\\\nTest text: {{test_text}}\")\n",
        "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
        "if torch.cuda.is_available():\n",
        "    inputs = {{k: v.to(\"cuda\") for k, v in inputs.items()}}\n",
        "\n",
        "print(f\"Token IDs: {{inputs['input_ids']}}\")\n",
        "decoded = tokenizer.decode(inputs['input_ids'][0])\n",
        "print(f\"Decoded: {{decoded}}\")\n",
        "\n",
        "# Test inference\n",
        "print(\"\\\\nRunning inference...\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(**inputs, max_new_tokens=20, do_sample=False)\n",
        "    \n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(f\"Generated text: {{generated_text}}\")\n",
        "print(f\"Output shape: {{outputs.shape}}\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"Code to execute on remote instance:\")\n",
        "print(\"=\" * 60)\n",
        "print(remote_code)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# If SSH is configured, save to remote file and execute:\n",
        "# remote_script = \"/tmp/test_model.py\"\n",
        "# # Write script to remote\n",
        "# execute_ssh_command(SSH_HOST, SSH_PORT, SSH_USER, f\"cat > {remote_script} << 'EOF'\\n{remote_code}\\nEOF\")\n",
        "# # Execute script\n",
        "# output, error, status = execute_ssh_command(SSH_HOST, SSH_PORT, SSH_USER, f\"python {remote_script}\")\n",
        "# print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Cleanup and Teardown\n",
        "\n",
        "**IMPORTANT:** Always destroy the instance when done to avoid unexpected charges!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate approximate cost (if runtime is tracked)\n",
        "start_time_track = time.time()  # Should be set when instance was launched\n",
        "runtime_minutes = (time.time() - start_time_track) / 60\n",
        "hourly_price = selected_price if 'selected_price' in locals() else 0\n",
        "estimated_cost = (runtime_minutes / 60) * hourly_price\n",
        "\n",
        "print(f\"Instance runtime: ~{runtime_minutes:.1f} minutes\")\n",
        "print(f\"Estimated cost: ~${estimated_cost:.4f}\")\n",
        "print(\"\\n[WARNING] Destroying instance now to stop billing!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Destroy instance\n",
        "try:\n",
        "    result = client.destroy_instance(INSTANCE_ID)\n",
        "    print(f\"[OK] Instance {INSTANCE_ID} destroyed\")\n",
        "    print(f\"Result: {result}\")\n",
        "except AttributeError:\n",
        "    # Try alternative method names\n",
        "    try:\n",
        "        result = client.destroy_instances([INSTANCE_ID])\n",
        "        print(f\"[OK] Instance {INSTANCE_ID} destroyed\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to destroy instance: {e}\")\n",
        "        print(\"  Please manually destroy instance in Vast.ai console to avoid charges!\")\n",
        "        raise\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] Failed to destroy instance: {e}\")\n",
        "    print(\"  Please manually destroy instance in Vast.ai console to avoid charges!\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify instance is destroyed\n",
        "print(\"Verifying instance termination...\")\n",
        "time.sleep(5)  # Wait a moment\n",
        "\n",
        "try:\n",
        "    instances = client.show_instances()\n",
        "    instance_list = instances if isinstance(instances, list) else instances.get('instances', [])\n",
        "    \n",
        "    found = False\n",
        "    for inst in instance_list:\n",
        "        if isinstance(inst, dict) and str(inst.get('id')) == str(INSTANCE_ID):\n",
        "            found = True\n",
        "            status = inst.get('status', inst.get('state', 'unknown'))\n",
        "            print(f\"  Instance status: {status}\")\n",
        "            break\n",
        "    \n",
        "    if not found:\n",
        "        print(\"[OK] Instance no longer in active instances list (destroyed)\")\n",
        "    else:\n",
        "        print(\"[WARNING] Instance still appears in list - verify in Vast.ai console\")\n",
        "except Exception as e:\n",
        "    print(f\"[WARNING] Could not verify: {e}\")\n",
        "    print(\"  Please check Vast.ai console manually\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "âœ… **Completed:**\n",
        "- Searched for cheapest A100 instance (<$1/hr)\n",
        "- Launched instance on Vast.ai\n",
        "- Set up remote environment\n",
        "- Downloaded and tested HuggingFace model (GPT-2)\n",
        "- Tested tokenization and inference\n",
        "- Cleaned up by destroying instance\n",
        "\n",
        "**Notes:**\n",
        "- SSH connection setup may require additional configuration in practice\n",
        "- Consider using Vast.ai's Jupyter interface as an alternative to SSH\n",
        "- Always verify instance destruction to avoid unexpected charges\n",
        "- Monitor your Vast.ai dashboard for actual costs\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
